{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GageBrady92/CS361/blob/main/object_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quick check to make sure GPU set up."
      ],
      "metadata": {
        "id": "N2H6YcFWW3LT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "9Dem8PXrWFQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFSeBXvhRvMY"
      },
      "source": [
        "Clone the TensorFlow git repo to make use of the API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bg2z-02LIsRt"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jCq7Xo-Rz1h"
      },
      "source": [
        "Install tensorflow API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0w4nq1QRIls"
      },
      "outputs": [],
      "source": [
        "%cd /content/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "# Install TensorFlow Object Detection API.\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VC0Jv34R6TD"
      },
      "source": [
        "Quick test to ensure API installed properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9tv2JGXRc38"
      },
      "outputs": [],
      "source": [
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up to pull from kaggle and link to kaggle API token.\n",
        "Created directory for kaggle.json\n",
        "------\n",
        "If issue here, try expire on kaggle and making new API token. Will need to update api token."
      ],
      "metadata": {
        "id": "v1Wz2i0V9q0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "Gllrt93l7HQW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "api_token = {\"username\":\"gagebrady\",\"key\":\"3af4e653371aeff5e41619cb5c3b5263\"}\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "i2VqNJ3CppUR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this to make directory, go into directory and unzip files to be used. Have the image files, annotations, CSV and python code to convert data to binary for tensorflow. This saves time by having all that is needed in one spot to pull from."
      ],
      "metadata": {
        "id": "6HeGG3cQHOdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "mkdir /content/dataset\n",
        "cd /content/dataset\n",
        "kaggle datasets download -d gagebrady/brain-mri-tumor-data --unzip"
      ],
      "metadata": {
        "id": "halEVFQH9AAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "id": "PJqcuVXR_v3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6bfa5b-65ba-4146-a164-da5125569dbf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create labelmap.pbtxt file and add text below.\n",
        "\n",
        "item {\n",
        "    name: \"tumor\"\n",
        "    id: 1\n",
        "}"
      ],
      "metadata": {
        "id": "q5gCi_4bHefX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!touch labelmap.pbtxt"
      ],
      "metadata": {
        "id": "ibB2VispCsEe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These commands convert CSV of image annotations to be passed to tensorflow object detection API."
      ],
      "metadata": {
        "id": "TLBcnEJgDt5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python dataset/generate_tf_records.py -l /content/labelmap.pbtxt -o dataset/train.record -i dataset/images -csv dataset/train_labels.csv\n",
        "!python dataset/generate_tf_records.py -l /content/labelmap.pbtxt -o dataset/test.record -i dataset/images -csv dataset/test_labels.csv"
      ],
      "metadata": {
        "id": "gIkz3ela_75a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and set up the model that will be trained."
      ],
      "metadata": {
        "id": "qjwNg7SOIJYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!wget http://download.tensorflow.org/models/object_detection/classification/tf2/20200710/mobilenet_v2.tar.gz\n",
        "!tar -xvf mobilenet_v2.tar.gz\n",
        "!rm mobilenet_v2.tar.gz"
      ],
      "metadata": {
        "id": "Ua0hdpPSHskH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_mobilenet_v2_320x320_coco17_tpu-8.config\n",
        "!mv ssd_mobilenet_v2_320x320_coco17_tpu-8.config mobilenet_v2.config"
      ],
      "metadata": {
        "id": "B-1219gQKoun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating paths and parameters and then configuring training file.\n",
        "Only checking for one class, which is tumors. Keeping batch size small to avoid memory issues that will stop the execution.\n",
        "This also configures for the specific model being used, mobilenet_v2."
      ],
      "metadata": {
        "id": "oBb1NyNeIqRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 1\n",
        "batch_size = 16\n",
        "num_steps = 6200\n",
        "num_eval_steps = 1000\n",
        "\n",
        "train_record_path = '/content/dataset/train.record'\n",
        "test_record_path = '/content/dataset/test.record'\n",
        "model_dir = '/content/training/'\n",
        "labelmap_path = '/content/labelmap.pbtxt'\n",
        "\n",
        "pipeline_config_path = 'mobilenet_v2.config'\n",
        "fine_tune_checkpoint = '/content/mobilenet_v2/mobilenet_v2.ckpt-1'\n",
        "\n"
      ],
      "metadata": {
        "id": "FDAuxjQoIUcj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "with open(pipeline_config_path) as f:\n",
        "    config = f.read()\n",
        "\n",
        "with open(pipeline_config_path, 'w') as f:\n",
        "\n",
        "  # Set labelmap path\n",
        "  config = re.sub('label_map_path: \".*?\"',\n",
        "             'label_map_path: \"{}\"'.format(labelmap_path), config)\n",
        "\n",
        "  # Set fine_tune_checkpoint path\n",
        "  config = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "                  'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), config)\n",
        "\n",
        "  # Set train tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")',\n",
        "                  'input_path: \"{}\"'.format(train_record_path), config)\n",
        "\n",
        "  # Set test tf-record file path\n",
        "  config = re.sub('(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")',\n",
        "                  'input_path: \"{}\"'.format(test_record_path), config)\n",
        "\n",
        "  # Set number of classes.\n",
        "  config = re.sub('num_classes: [0-9]+',\n",
        "                  'num_classes: {}'.format(num_classes), config)\n",
        "\n",
        "  # Set batch size\n",
        "  config = re.sub('batch_size: [0-9]+',\n",
        "                  'batch_size: {}'.format(batch_size), config)\n",
        "\n",
        "  # Set training steps\n",
        "  config = re.sub('num_steps: [0-9]+',\n",
        "                  'num_steps: {}'.format(num_steps), config)\n",
        "\n",
        "  f.write(config)"
      ],
      "metadata": {
        "id": "_0XXU_ImIeFA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Right now have to install older version of tensorflow to make use of flow."
      ],
      "metadata": {
        "id": "lecpQlEfd-k9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.13.0"
      ],
      "metadata": {
        "id": "zk5d4kAjdmij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code starts the process of training the model. With current setup, doing batches of 2 with 7500 steps."
      ],
      "metadata": {
        "id": "Tnx2uEGfoSvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_config_path} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1 \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "metadata": {
        "id": "d2d8ZRO7Izxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This checks the models performance and calculates loss. Lower the loss, better the accuracy"
      ],
      "metadata": {
        "id": "_1swG_p9oYuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_config_path} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --checkpoint_dir={model_dir}"
      ],
      "metadata": {
        "id": "94mCMOVcMt3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will create simple graphs to represent the model training."
      ],
      "metadata": {
        "id": "jk3ZcLVlog-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/training/'"
      ],
      "metadata": {
        "id": "Rv3ysbThNyKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Right now have to manually create folders and upload them to the notebook.\n",
        "Once done, can move to the next step."
      ],
      "metadata": {
        "id": "tF2TjB6KOMz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/hugozanini/object-detection/master/inferenceutils.py\n",
        "from inferenceutils import *"
      ],
      "metadata": {
        "id": "WtNj87uLAecA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_directory = 'inference_graph/'"
      ],
      "metadata": {
        "id": "onmseUsoAijF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(labelmap_path, use_display_name=True)\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.saved_model.load(f'/content/{output_directory}/saved_model')"
      ],
      "metadata": {
        "id": "dwpLUuejAl-t"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code selects 3 random photos from test_lables.csv"
      ],
      "metadata": {
        "id": "NHLSuvhWOhfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test = pd.read_csv('/content/dataset/test_labels.csv')\n",
        "#Getting 3 random images to test\n",
        "images = list(test.sample(n=3)['filename'])"
      ],
      "metadata": {
        "id": "lc3dy6BJApDd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code runs the model on the images provided and highlights object. Accuracy is a bit low, so may need to retrain the model."
      ],
      "metadata": {
        "id": "3cbIonc9OmkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for image_name in images:\n",
        "\n",
        "  image_np = load_image_into_numpy_array('/content/dataset/images/' + image_name)\n",
        "  output_dict = run_inference_for_single_image(model, image_np)\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8)\n",
        "  display(Image.fromarray(image_np))"
      ],
      "metadata": {
        "id": "KDg21RZlArp3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "mount_file_id": "1tRqvT9qaI4nXWSsUKcyPXQknqdaYs0pP",
      "authorship_tag": "ABX9TyO6esVu+8tDULp0uB2nHtm9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}